{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFPLvJ9u371s"
   },
   "source": [
    "# Script to Scrape News Text from GKG URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOIGU7-PwDzb"
   },
   "outputs": [],
   "source": [
    "# !pip install -q git+https://github.com/codelucas/newspaper.git\n",
    "# !pip install -q readability-lxml\n",
    "\n",
    "# !pip install -q urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRyXBsBk371y"
   },
   "outputs": [],
   "source": [
    "# !pip install -q pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G97F-UeKLifl"
   },
   "outputs": [],
   "source": [
    "# import gdelt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import numpy as  np\n",
    "import time\n",
    "from random import randint\n",
    "import urllib\n",
    "import re \n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from pandarallel import pandarallel\n",
    "import multiprocessing\n",
    "\n",
    "import gc\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qj7cNtqnHUM"
   },
   "source": [
    "# SCRAPE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAijXI9nWGtT"
   },
   "outputs": [],
   "source": [
    "# load GKG file\n",
    "country_news_alt = pd.read_csv('../../kenya_aug2016_nov2017.csv',\n",
    "                               lineterminator='\\n', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3p_DXD3WR2T"
   },
   "outputs": [],
   "source": [
    "country_news_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gu3xF5ztmS-u"
   },
   "outputs": [],
   "source": [
    "country_news_alt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jbn45Pn_mQGn"
   },
   "outputs": [],
   "source": [
    "# plot volume of data\n",
    "\n",
    "plt.figure(figsize=(22,8))\n",
    "sns.histplot(country_news_alt.DATE)\n",
    "plt.title('Volume of related text in selected period')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Qzzw7l7uGfg",
    "outputId": "3612a894-61db-4763-dcb5-4e84fc306dfa",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/williamsimpson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Base scraper\n",
    "\n",
    "# Modified from...\n",
    "# Author: Linwood Creekmore\n",
    "# Email: valinvescap@gmail.com\n",
    "# Description:  Python script to pull content from a website (works on news stories).\n",
    "\n",
    "###################################\n",
    "# Standard Library imports\n",
    "###################################\n",
    "\n",
    "import re\n",
    "import pytz\n",
    "import datetime\n",
    "import platform\n",
    "\n",
    "\n",
    "###################################\n",
    "# Third party imports\n",
    "###################################\n",
    "\n",
    "import requests\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "from readability.readability import Document as Paper\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "\n",
    "done = {}\n",
    "\n",
    "\n",
    "def textgetter(url):\n",
    "    \"\"\"Scrapes web news and returns the content\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        web address to news report\n",
    "    Returns \n",
    "    -------\n",
    "    \n",
    "    answer : dict\n",
    "        Python dictionary with key/value pairs for:\n",
    "            text (str) - Full text of article\n",
    "            url (str) - url to article\n",
    "            title (str) - extracted title of article\n",
    "            author (str) - name of extracted author(s)\n",
    "            base (str) - base url of where article was located\n",
    "            provider (str) - string of the news provider from url\n",
    "            published_date (str,isoformat) - extracted date of article\n",
    "            top_image (str) - extracted url of the top image for article\n",
    "    \"\"\"\n",
    "    global done\n",
    "    TAGS = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'p', 'li']\n",
    "\n",
    "    # regex for url check\n",
    "    s = re.compile('(http://|https://)([A-Za-z0-9_\\.-]+)')\n",
    "    u = re.compile(\"(http://|https://)(www.)?(.*)(\\.[A-Za-z0-9]{1,4})$\")\n",
    "    if s.search(url):\n",
    "        site = u.search(s.search(url).group())\n",
    "        if u.search(s.search(url).group()) is not None:\n",
    "            site = site.group(3)\n",
    "    else:\n",
    "        site = None\n",
    "    answer = {}\n",
    "    # check that its an url\n",
    "    if s.search(url):\n",
    "        if url in done.keys():\n",
    "            yield done[url]\n",
    "            pass\n",
    "        try:\n",
    "            # make a request to the url\n",
    "            r = requests.get(url, verify=False, timeout=1)\n",
    "        except:\n",
    "            # if the url does not return data, set to empty values\n",
    "            done[url] = \"Unable to reach website.\"\n",
    "            answer['author'] = None\n",
    "            answer['base'] = s.search(url).group()\n",
    "            answer['provider']=site\n",
    "            answer['published_date']=None\n",
    "            answer['text'] = \"Unable to reach website.\"\n",
    "            answer['title'] = None\n",
    "            answer['top_image'] = None\n",
    "            answer['url'] = url\n",
    "            answer['keywords']=None\n",
    "            answer['summary']=None\n",
    "            yield answer\n",
    "        # if url does not return successfully, set ot empty values\n",
    "        if r.status_code != 200:\n",
    "            done[url] = \"Unable to reach website.\"\n",
    "            answer['author'] = None\n",
    "            answer['base'] = s.search(url).group()\n",
    "            answer['provider']=site\n",
    "            answer['published_date']=None\n",
    "            answer['text'] = \"Unable to reach website.\"\n",
    "            answer['title'] = None\n",
    "            answer['top_image'] = None\n",
    "            answer['url'] = url\n",
    "            answer['keywords']=None\n",
    "            answer['summary']=None\n",
    "\n",
    "        # test if length of url content is greater than 500, if so, fill data\n",
    "        if len(r.content)>500:\n",
    "            # set article url\n",
    "            article = Article(url)\n",
    "            # test for python version because of html different parameters\n",
    "            if int(platform.python_version_tuple()[0])==3:\n",
    "                article.download(input_html=r.content)\n",
    "            elif int(platform.python_version_tuple()[0])==2:\n",
    "                article.download(html=r.content)\n",
    "            # parse the url\n",
    "            article.parse()\n",
    "            article.nlp()\n",
    "            # if parse doesn't pull text fill the rest of the data\n",
    "            if len(article.text) >= 200:\n",
    "                answer['author'] = \", \".join(article.authors)\n",
    "                answer['base'] = s.search(url).group()\n",
    "                answer['provider']=site\n",
    "                answer['published_date'] = article.publish_date\n",
    "                answer['keywords']=article.keywords\n",
    "                answer['summary']=article.summary\n",
    "                # convert the data to isoformat; exception for naive date\n",
    "                if isinstance(article.publish_date,datetime.datetime):\n",
    "                    try:\n",
    "                        answer['published_date']=article.publish_date.astimezone(pytz.utc).isoformat()\n",
    "                    except:\n",
    "                        answer['published_date']=article.publish_date.isoformat()\n",
    "                \n",
    "\n",
    "                answer['text'] = article.text\n",
    "                answer['title'] = article.title\n",
    "                answer['top_image'] = article.top_image\n",
    "                answer['url'] = url\n",
    "                \n",
    "                \n",
    "\n",
    "            # if previous didn't work, try another library\n",
    "            else:\n",
    "                doc = Paper(r.content)\n",
    "                data = doc.summary()\n",
    "                title = doc.title()\n",
    "                soup = BeautifulSoup(data, 'lxml')\n",
    "                newstext = \" \".join([l.text for l in soup.find_all(TAGS)])\n",
    "\n",
    "                # as we did above, pull text if it's greater than 200 length\n",
    "                if len(newstext) > 200:\n",
    "                    answer['author'] = None\n",
    "                    answer['base'] = s.search(url).group()\n",
    "                    answer['provider']=site\n",
    "                    answer['published_date']=None\n",
    "                    answer['text'] = newstext\n",
    "                    answer['title'] = title\n",
    "                    answer['top_image'] = None\n",
    "                    answer['url'] = url\n",
    "                    answer['keywords']=None\n",
    "                    answer['summary']=None\n",
    "                # if nothing works above, use beautiful soup\n",
    "                else:\n",
    "                    newstext = \" \".join([\n",
    "                        l.text\n",
    "                        for l in soup.find_all(\n",
    "                            'div', class_='field-item even')\n",
    "                    ])\n",
    "                    done[url] = newstext\n",
    "                    answer['author'] = None\n",
    "                    answer['base'] = s.search(url).group()\n",
    "                    answer['provider']=site\n",
    "                    answer['published_date']=None\n",
    "                    answer['text'] = newstext\n",
    "                    answer['title'] = title\n",
    "                    answer['top_image'] = None\n",
    "                    answer['url'] = url\n",
    "                    answer['keywords']=None\n",
    "                    answer['summary']=None\n",
    "        # if nothing works, fill with empty values\n",
    "        else:\n",
    "            answer['author'] = None\n",
    "            answer['base'] = s.search(url).group()\n",
    "            answer['provider']=site\n",
    "            answer['published_date']=None\n",
    "            answer['text'] = 'No text returned'\n",
    "            answer['title'] = None\n",
    "            answer['top_image'] = None\n",
    "            answer['url'] = url\n",
    "            answer['keywords']=None\n",
    "            answer['summary']=None\n",
    "            yield answer\n",
    "        yield answer\n",
    "\n",
    "    # the else clause to catch if invalid url passed in\n",
    "    else:\n",
    "        answer['author'] = None\n",
    "        answer['base'] = s.search(url).group()\n",
    "        answer['provider']=site\n",
    "        answer['published_date']=None\n",
    "        answer['text'] = 'This is not a proper url'\n",
    "        answer['title'] = None\n",
    "        answer['top_image'] = None\n",
    "        answer['url'] = url\n",
    "        answer['keywords']=None\n",
    "        answer['summary']=None\n",
    "        yield answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gpd6cOKh3716"
   },
   "outputs": [],
   "source": [
    "# Outer scraper function \n",
    "\n",
    "def scrape_news_v2(row):\n",
    "    '''\n",
    "    Provides logic to check success of scrapes and rescrape if necessary\n",
    "    First trys to scrape from the Way Back Machine\n",
    "    If that is not successful, it scrapes from the live url\n",
    "    Provides flags to indicate provenance of articles \n",
    "    \n",
    "    Parameters:\n",
    "    ———————————\n",
    "    row: str\n",
    "        a URL\n",
    "    \n",
    "    Outputs:\n",
    "    ————————\n",
    "    scrape_news_art: str\n",
    "        the text of the article\n",
    "    flag_art: int\n",
    "        indicates if the text was obtained successfully and identifies source of failure\n",
    "    wbm_tag: int\n",
    "        indicates if the article was scraped from the Way Back Machine \n",
    "    '''\n",
    "    url = row\n",
    "    try:\n",
    "        # get first url if multiple \n",
    "        if re.findall('<UDIV>',url):\n",
    "            url = re.findall(r'.+?(?=<UDIV>)', url)[0]\n",
    "        # find Way Back Machine version of url if available\n",
    "        way_back_machine_url = f'http://archive.org/wayback/available?url={url}'\n",
    "        r = requests.get(way_back_machine_url)\n",
    "        response_json = r.json()\n",
    "        #print(response_json)\n",
    "        # no url returned from WBM\n",
    "        if len(response_json['archived_snapshots'])<1:\n",
    "            # use original url and run scrape twice\n",
    "            scrape_news_art, flag_art, wbm_tag = get_text(url)\n",
    "            scrape_news_art, flag_art, wbm_tag = get_text(url)\n",
    "            # mark that this is not from the wbm\n",
    "            wbm_tag = 0\n",
    "            \n",
    "        else:\n",
    "            snapshot_url = response_json['archived_snapshots']['closest']['url']    \n",
    "            scrape_news_art, flag_art, wbm_tag = get_text(snapshot_url)\n",
    "            # if WBM did not work try plain url\n",
    "            if re.findall('Unable to reach website', scrape_news_art):\n",
    "                # use original url and run scrape twice\n",
    "                scrape_news_art, flag_art, wbm_tag = get_text(url)\n",
    "                scrape_news_art, flag_art, wbm_tag = get_text(url)\n",
    "                # mark that this is not from the wbm\n",
    "                wbm_tag = 0\n",
    "        # sleep \n",
    "        time.sleep(randint(2,7))    \n",
    "        \n",
    "        return scrape_news_art, flag_art, wbm_tag\n",
    "    \n",
    "    except:\n",
    "        #print('>>>FAILED at:',url)\n",
    "        return 'ALL FAIL', -1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAPS6cuD3716"
   },
   "outputs": [],
   "source": [
    "# Helper function for scrape_news_v2 function\n",
    "\n",
    "def get_text(row):\n",
    "    '''\n",
    "    Wraps the base scraper function and\n",
    "    provides logic to track possible points of failure in the scrape\n",
    "    \n",
    "    Parameters:\n",
    "    ———————————\n",
    "    row: str\n",
    "        a URL\n",
    "    \n",
    "    Outputs:\n",
    "    ————————\n",
    "    text: str\n",
    "        the text of the article\n",
    "    flag: int\n",
    "        indicates if the text was obtained successfully and identifies source of failure\n",
    "    tag: int\n",
    "        indicates if the article was scraped from the Way Back Machine\n",
    "    '''\n",
    "    url = row\n",
    "    try:\n",
    "        # check if resembles url\n",
    "        if not url.startswith('http'):\n",
    "            text = 'NOT URL'\n",
    "            flag = -2\n",
    "            tag = 1\n",
    "            return text, flag, tag \n",
    "        \n",
    "        # scrape url\n",
    "        text = next(textgetter(url))\n",
    "        \n",
    "        # check if url worked\n",
    "        if len(text) == 0:\n",
    "            text = 'No dict from scraper'\n",
    "            flag = -3\n",
    "            tag = 1\n",
    "            return text, flag, tag\n",
    "        # url worked but no text returned\n",
    "        elif text == 'Unable to reach website.' or text == 'Unable to reach website. ':\n",
    "            flag = -4\n",
    "            tag = 1\n",
    "            return text, flag, tag\n",
    "        # if link works\n",
    "        else:\n",
    "            # get text\n",
    "            text = text['text']\n",
    "            # if text returned is empty\n",
    "            if len(text) < 1:\n",
    "                text = 'No text returned'\n",
    "                flag = -5\n",
    "                tag = 1\n",
    "                return text, flag, tag\n",
    "            # if scraper returns 'no text returned'\n",
    "            elif text == 'No text returned' or text == 'No text returned ':\n",
    "                text = 'No text returned'\n",
    "                flag = -6\n",
    "                tag = 1\n",
    "                return text, flag, tag\n",
    "            # got text as expected\n",
    "            else:  \n",
    "                flag = 1 \n",
    "                tag = 1\n",
    "                return text, flag, tag\n",
    "        \n",
    "    except:\n",
    "        #print('>>>FAILED at:',url)\n",
    "        return 'ALL FAIL', -7, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ax2y64k3z40-"
   },
   "outputs": [],
   "source": [
    "# basic clean news text function\n",
    "\n",
    "def clean_txt(txt):\n",
    "    '''\n",
    "    Removes newline characters\n",
    "    \n",
    "    Parameters:\n",
    "    ———————————\n",
    "    txt: str\n",
    "        original text\n",
    "    \n",
    "    Outputs:\n",
    "    ————————\n",
    "    txt: str\n",
    "        clean text\n",
    "    '''\n",
    "    txt = re.sub('\\\\n+', ' ', txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7axi5Bt3717",
    "outputId": "e3261c09-8e14-4b0c-bdc0-5405dfdcd736"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for parallelization\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoz9ShXS3717",
    "outputId": "5c3f6640-9521-447f-9a6c-bd94fb316ca6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# intialize parallel computation\n",
    "\n",
    "pandarallel.initialize(nb_workers=num_cores, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86-lG0ut3718"
   },
   "outputs": [],
   "source": [
    "# SUPER-BATCH FOR THIS MACHINE\n",
    "\n",
    "# update the slice of the dataframe once each super-batch is complete\n",
    "# If overall dataset is small enough this could be the entire dataset\n",
    "# Otherwise you will have to recombine the datasets afterwards \n",
    "# After each super-batch you should move the saved files to another folder\n",
    "# Else they will be overwritten the next time you run the scraping script\n",
    "# Once the super-batch is successfully complete, you can delete all but the last output file \n",
    "# This is because the script appends each batch to the previous output file\n",
    "\n",
    "country_news_alt = country_news_alt[:10000]\n",
    "country_news_alt.reset_index(inplace=True, drop=True)\n",
    "country_news_alt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "c1536ef187364139888ad618b40a4656",
      "2c65ab4f3ad549269ae032dad6c48d99",
      "79c27ff764ed4398b3de81b0b24c9ab2",
      "6122214738604fae81b3e959d8874a4e",
      "0bef5d16a4fb400496d5a42d2c73da24",
      "34cf33f6fe914b38a05d0724001445d0",
      "0c297d37b5ea43f5b6d1b2bfff972b77",
      "c20f40924a054994bf0e2363ce409f44",
      "bf2b619c673a48dc9324bb2e34a98fad",
      "7061a704958046508eb0dac990b46ab8",
      "33caf8a66f234dd9a7785f8de40e3d48",
      "abe6eec78c9541b6a951099b6c0a8dc3",
      "9e5c3c2a1838412ab13b1b4ae62e9fa9",
      "855b52aa3ae94b0b8e4a76cfdec01227",
      "bd00e61f1d96446ca0905d49eee5f3a6",
      "dfe7e1336e994ff2ad3c32d1b1bda9a1",
      "77d1f872f14c471e954d1741cb99ff65",
      "b22405441205460c84212e1ca8677158",
      "9941b201e7ef49c185a8b8e87078c694",
      "9ca11012ca9b4413bd34fe771dc6e0f0",
      "78fd13fbe10749e29bd8254f21ccbccf",
      "c11fd85ea24e44f1bc2dbbc5401b1ae7",
      "de7c3dd4190f4b31924e81d51c3c1fc8",
      "67e85f3b0188475c9ee49e2ccadb6ddb",
      "8c9b46965e7d4a4d99c7a5422b81470a",
      "a0de664e016940c59bff644c4ba424d6",
      "23ae71b1ae2547f296469d14448ba574",
      "22a2751c893d4c42bf96f3dcb3a8fb84",
      "b41db148fd204e5db0c1d0e7867b6082",
      "866777ec20364f74b84baed8fba06f78",
      "9415cff6550d45f4a7f88a866f5aee6a",
      "3532e225f4064ba49cf6a29c7b91396b"
     ]
    },
    "id": "fwnrxSel3718",
    "outputId": "9130df23-a27c-45e0-aa2c-f1c197cd19c7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1536ef187364139888ad618b40a4656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c65ab4f3ad549269ae032dad6c48d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 715. Skipping tag 59932\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:792: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 1739. Skipping tag 59932\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 546. Skipping tag 59932\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 1570. Skipping tag 59932\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c27ff764ed4398b3de81b0b24c9ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 656. Skipping tag 59932\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:792: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 1680. Skipping tag 59932\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 136. Skipping tag 59932\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 1160. Skipping tag 59932\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 4 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6122214738604fae81b3e959d8874a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2942: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2942: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 5 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bef5d16a4fb400496d5a42d2c73da24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 6 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cf33f6fe914b38a05d0724001445d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 7 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c297d37b5ea43f5b6d1b2bfff972b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20f40924a054994bf0e2363ce409f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname IST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2942: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2942: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2b619c673a48dc9324bb2e34a98fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7061a704958046508eb0dac990b46ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2942: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33caf8a66f234dd9a7785f8de40e3d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe6eec78c9541b6a951099b6c0a8dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 13 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5c3c2a1838412ab13b1b4ae62e9fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855b52aa3ae94b0b8e4a76cfdec01227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 15 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd00e61f1d96446ca0905d49eee5f3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 438 bytes but only got 290. Skipping tag 37500\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 42034\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 42035\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 34 bytes but only got 0. Skipping tag 42036\n",
      "  warnings.warn(\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 16 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe7e1336e994ff2ad3c32d1b1bda9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 33434\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 33437\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 36867\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 36868\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37377\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37378\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37380\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 37386\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:792: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
      "  warnings.warn(str(msg))\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 17 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d1f872f14c471e954d1741cb99ff65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname IST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 18 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22405441205460c84212e1ca8677158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1213: UnknownTimezoneWarning: tzname IST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2942: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 19 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9941b201e7ef49c185a8b8e87078c694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca11012ca9b4413bd34fe771dc6e0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 21 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78fd13fbe10749e29bd8254f21ccbccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 22 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11fd85ea24e44f1bc2dbbc5401b1ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2942: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 23 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7c3dd4190f4b31924e81d51c3c1fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 24 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e85f3b0188475c9ee49e2ccadb6ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2942: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 25 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9b46965e7d4a4d99c7a5422b81470a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 26 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0de664e016940c59bff644c4ba424d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 264 bytes but only got 150. Skipping tag 37510\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41486\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41487\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 13 bytes but only got 0. Skipping tag 42033\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 42034\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 42036\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11 bytes but only got 0. Skipping tag 42037\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 27 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ae71b1ae2547f296469d14448ba574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 700. Skipping tag 59932\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:792: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 1724. Skipping tag 59932\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 534. Skipping tag 59932\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2060 bytes but only got 1558. Skipping tag 59932\n",
      "  warnings.warn(\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 28 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a2751c893d4c42bf96f3dcb3a8fb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py:2942: UserWarning: image file could not be identified because WEBP support not installed\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 29 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41db148fd204e5db0c1d0e7867b6082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 30 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866777ec20364f74b84baed8fba06f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 31 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9415cff6550d45f4a7f88a866f5aee6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 32 of 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3532e225f4064ba49cf6a29c7b91396b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=63), Label(value='0 / 63'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrape in Batches \n",
    "\n",
    "# The only variable you should need to change is the batch size as needed\n",
    "# change file paths as needed\n",
    "\n",
    "# define batch variables \n",
    "idx = 0\n",
    "batch_size = 500  \n",
    "total_articles = country_news_alt.shape[0]\n",
    "num_batches = math.ceil(total_articles / batch_size)\n",
    "\n",
    "for batch in range(num_batches):\n",
    "    print('Batch:', batch+1,'of',num_batches)\n",
    "    # load previous batch\n",
    "    if batch == 0:\n",
    "        prev_batch_df = pd.DataFrame()\n",
    "    else:\n",
    "        prev_batch_df = pd.read_csv(f'../../data_large/scrape_news_df_batch_{batch-1}.csv', lineterminator='\\n', index_col=0)\n",
    "  \n",
    "    # instatiate vals\n",
    "    curr_batch_df = country_news_alt[idx:idx+batch_size].copy()\n",
    "\n",
    "    # scrape news per batch \n",
    "    scrape_news_art_flags_tags = country_news_alt['SOURCEURLS'][idx:idx+batch_size].parallel_apply(scrape_news_v2)\n",
    "    scrape_news_art = [scrape_news_art_flags_tags[i+idx][0] for i in range(len(scrape_news_art_flags_tags))]\n",
    "    flags_art = [scrape_news_art_flags_tags[i+idx][1] for i in range(len(scrape_news_art_flags_tags))]\n",
    "    tags_art = [scrape_news_art_flags_tags[i+idx][2] for i in range(len(scrape_news_art_flags_tags))]\n",
    "\n",
    "    # clean batch\n",
    "    news_per_batch_clean = [clean_txt(str(tx)) for tx in scrape_news_art]\n",
    "\n",
    "    # store batch\n",
    "    curr_batch_df['news_text'] = news_per_batch_clean\n",
    "    curr_batch_df['scraping_flag'] = flags_art\n",
    "    curr_batch_df['wbm_tag'] = tags_art\n",
    "    output_batch_df = prev_batch_df.append(curr_batch_df)\n",
    "\n",
    "    # write batch to disk\n",
    "    output_batch_df.to_csv(f'../../data_large/scrape_news_df_batch_{batch}.csv')\n",
    "\n",
    "    # unpdate indices for next batch\n",
    "    idx += batch_size\n",
    "\n",
    "    # sleep \n",
    "    time.sleep(randint(10,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_aSYgHWU3719"
   },
   "source": [
    "# View Example Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfTYHXah3719"
   },
   "outputs": [],
   "source": [
    "# view df with scraped text\n",
    "\n",
    "country_news_latest = pd.read_csv('../../data_large/scrape_news_df_batch_49.csv',\n",
    "                               lineterminator='\\n', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8wXRGrU3719",
    "outputId": "00ceb70d-60c9-41d7-d79c-1d9dddc7ddbb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>NUMARTS</th>\n",
       "      <th>COUNTS</th>\n",
       "      <th>THEMES</th>\n",
       "      <th>LOCATIONS</th>\n",
       "      <th>PERSONS</th>\n",
       "      <th>ORGANIZATIONS</th>\n",
       "      <th>TONE</th>\n",
       "      <th>CAMEOEVENTIDS</th>\n",
       "      <th>SOURCES</th>\n",
       "      <th>SOURCEURLS</th>\n",
       "      <th>news_text</th>\n",
       "      <th>scraping_flag</th>\n",
       "      <th>wbm_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TAX_FNCACT;TAX_FNCACT_ACTRESS;TAX_ETHNICITY;TA...</td>\n",
       "      <td>4#Uhuru, Nairobi Area, Kenya#KE#KE05#-1.28333#...</td>\n",
       "      <td>john okafor;kenneth okwonko;tonto dikeh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.83687943262411,4.25531914893617,1.4184397163...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247nigerianewsupdate.co</td>\n",
       "      <td>http://www.247nigerianewsupdate.co/2017/07/see...</td>\n",
       "      <td>Unable to reach website.</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TAX_ECON_PRICE;EPU_ECONOMY_HISTORIC;TAX_ETHNIC...</td>\n",
       "      <td>1#Burundi#BY#BY#-3.5#30#BY;1#Rwanda#RW#RW#-2#3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>netherlands africa business council;africa eve...</td>\n",
       "      <td>2.04081632653061,2.33236151603499,0.2915451895...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cta.int</td>\n",
       "      <td>http://brussels.cta.int/index.php?option=com_k...</td>\n",
       "      <td>Unable to reach website.</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TAX_FNCACT;TAX_FNCACT_WOMEN;USPEC_POLITICS_GEN...</td>\n",
       "      <td>4#Nairobi, Nairobi Area, Kenya#KE#KE05#-1.2833...</td>\n",
       "      <td>millie odhiambo mbita;johanna ngeno emurua dik...</td>\n",
       "      <td>orange democratic movement;nairobi county at k...</td>\n",
       "      <td>-0.164473684210526,3.61842105263158,3.78289473...</td>\n",
       "      <td>672052169,672052170,672052205,672053130,672032...</td>\n",
       "      <td>sde.co.ke;sde.co.ke</td>\n",
       "      <td>https://www.sde.co.ke/article/2001246965/how-k...</td>\n",
       "      <td>Ida Odinga, Margaret Kenyatta and Rachel Ruto ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WB_135_TRANSPORT;TAX_FNCACT;TAX_FNCACT_DRIVERS...</td>\n",
       "      <td>1#Uganda#UG#UG#1#32#UG;1#Kenya#KE#KE#1#38#KE</td>\n",
       "      <td>fernando wangila</td>\n",
       "      <td>public service vehicles;technology management</td>\n",
       "      <td>-2.28571428571429,1.07142857142857,3.357142857...</td>\n",
       "      <td>672171132,672074694</td>\n",
       "      <td>techweez.com</td>\n",
       "      <td>http://www.techweez.com/2017/07/11/ntsa-smart-...</td>\n",
       "      <td>Kenya’s National Transport and Safety Board (N...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AGRICULTURE;TAX_FNCACT;TAX_FNCACT_FARMERS;UNGP...</td>\n",
       "      <td>4#Kericho, Central, Kenya#KE#KE01#-0.410736#37...</td>\n",
       "      <td>esther ruto;africa allafrica;rusi cheruiyot</td>\n",
       "      <td>comart foundation;coady international institut...</td>\n",
       "      <td>2.76710222905457,3.38201383551115,0.6149116064...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bizcommunity.com</td>\n",
       "      <td>http://www.bizcommunity.com/Article/196/356/16...</td>\n",
       "      <td>By adopting agroforestry and improved agricult...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TAX_ETHNICITY;TAX_ETHNICITY_KENYANS;EDUCATION;...</td>\n",
       "      <td>4#Nyamira, Nyanza, Kenya#KE#KE07#-0.083333#34....</td>\n",
       "      <td>musa mustapha;agnes mutiota;thomas nyakundi;os...</td>\n",
       "      <td>boundaries commission</td>\n",
       "      <td>-2.45022970903522,1.07197549770291,3.522205206...</td>\n",
       "      <td>678753308,678754466,678754467,678754469</td>\n",
       "      <td>standardmedia.co.ke</td>\n",
       "      <td>https://www.standardmedia.co.ke/article/200125...</td>\n",
       "      <td>Unable to reach website.</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>1</td>\n",
       "      <td>KILL#200##1#Kenya#KE#KE#1#38#KE;CRISISLEX_CRIS...</td>\n",
       "      <td>LEADER;TAX_FNCACT;TAX_FNCACT_PRESIDENT;USPEC_P...</td>\n",
       "      <td>1#Tanzania#TZ#TZ#-6#35#TZ;1#Kenya#KE#KE#1#38#K...</td>\n",
       "      <td>natasha stott despoja;gideon kayinamura;mwai k...</td>\n",
       "      <td>party leader australia professor pierre moukok...</td>\n",
       "      <td>0.574712643678161,3.06513409961686,2.490421455...</td>\n",
       "      <td>678599092,678599093,678542527,678599437,678599...</td>\n",
       "      <td>myjoyonline.com</td>\n",
       "      <td>https://www.myjoyonline.com/politics/2017/Augu...</td>\n",
       "      <td>No dict from scraper</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TAX_FNCACT;TAX_FNCACT_CHIEF;GENERAL_GOVERNMENT...</td>\n",
       "      <td>1#Rwanda#RW#RW#-2#30#RW;5#Gauteng, Gauteng, So...</td>\n",
       "      <td>addis abeba;carlo ladicicco;sol campbell</td>\n",
       "      <td>wide area networks;gauteng high court on</td>\n",
       "      <td>0,3.07692307692308,3.07692307692308,6.15384615...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>direct.news</td>\n",
       "      <td>https://africa.direct.news/news=933349</td>\n",
       "      <td>No text returned</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNGP_FORESTS_RIVERS_OCEANS;TAX_FNCACT;TAX_FNCA...</td>\n",
       "      <td>1#Mexico#MX#MX#23#-102#MX;2#New York, United S...</td>\n",
       "      <td>trudy coxe;jonathan soroff;jonathan kaye;iris ...</td>\n",
       "      <td>preservation society;preservation society of n...</td>\n",
       "      <td>6.04395604395604,7.14285714285714,1.0989010989...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>improper.com</td>\n",
       "      <td>http://www.improper.com/photos-parties/newport...</td>\n",
       "      <td>Unable to reach website.</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>1</td>\n",
       "      <td>PROTEST#21#Kenyan#1#Kenya#KE#KE#1#38#KE;MOVEME...</td>\n",
       "      <td>ELECTION;CORRUPTION;TAX_ETHNICITY;TAX_ETHNICIT...</td>\n",
       "      <td>4#Nairobi, Nairobi Area, Kenya#KE#KE05#-1.2833...</td>\n",
       "      <td>beatrice obwocha;boniface mwangi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.92678227360308,2.89017341040462,4.816955684...</td>\n",
       "      <td>678546220,678609757,678591897,678609760,678564...</td>\n",
       "      <td>en.rfi.fr</td>\n",
       "      <td>http://en.rfi.fr/africa/20170804-kenyan-activi...</td>\n",
       "      <td>Unable to reach website.</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE  NUMARTS                                             COUNTS  \\\n",
       "0      2017-07-11        1                                                NaN   \n",
       "1      2017-07-11        1                                                NaN   \n",
       "2      2017-07-11        2                                                NaN   \n",
       "3      2017-07-11        1                                                NaN   \n",
       "4      2017-07-11        1                                                NaN   \n",
       "...           ...      ...                                                ...   \n",
       "24995  2017-08-04        1                                                NaN   \n",
       "24996  2017-08-04        1  KILL#200##1#Kenya#KE#KE#1#38#KE;CRISISLEX_CRIS...   \n",
       "24997  2017-08-04        1                                                NaN   \n",
       "24998  2017-08-04        1                                                NaN   \n",
       "24999  2017-08-04        1  PROTEST#21#Kenyan#1#Kenya#KE#KE#1#38#KE;MOVEME...   \n",
       "\n",
       "                                                  THEMES  \\\n",
       "0      TAX_FNCACT;TAX_FNCACT_ACTRESS;TAX_ETHNICITY;TA...   \n",
       "1      TAX_ECON_PRICE;EPU_ECONOMY_HISTORIC;TAX_ETHNIC...   \n",
       "2      TAX_FNCACT;TAX_FNCACT_WOMEN;USPEC_POLITICS_GEN...   \n",
       "3      WB_135_TRANSPORT;TAX_FNCACT;TAX_FNCACT_DRIVERS...   \n",
       "4      AGRICULTURE;TAX_FNCACT;TAX_FNCACT_FARMERS;UNGP...   \n",
       "...                                                  ...   \n",
       "24995  TAX_ETHNICITY;TAX_ETHNICITY_KENYANS;EDUCATION;...   \n",
       "24996  LEADER;TAX_FNCACT;TAX_FNCACT_PRESIDENT;USPEC_P...   \n",
       "24997  TAX_FNCACT;TAX_FNCACT_CHIEF;GENERAL_GOVERNMENT...   \n",
       "24998  UNGP_FORESTS_RIVERS_OCEANS;TAX_FNCACT;TAX_FNCA...   \n",
       "24999  ELECTION;CORRUPTION;TAX_ETHNICITY;TAX_ETHNICIT...   \n",
       "\n",
       "                                               LOCATIONS  \\\n",
       "0      4#Uhuru, Nairobi Area, Kenya#KE#KE05#-1.28333#...   \n",
       "1      1#Burundi#BY#BY#-3.5#30#BY;1#Rwanda#RW#RW#-2#3...   \n",
       "2      4#Nairobi, Nairobi Area, Kenya#KE#KE05#-1.2833...   \n",
       "3           1#Uganda#UG#UG#1#32#UG;1#Kenya#KE#KE#1#38#KE   \n",
       "4      4#Kericho, Central, Kenya#KE#KE01#-0.410736#37...   \n",
       "...                                                  ...   \n",
       "24995  4#Nyamira, Nyanza, Kenya#KE#KE07#-0.083333#34....   \n",
       "24996  1#Tanzania#TZ#TZ#-6#35#TZ;1#Kenya#KE#KE#1#38#K...   \n",
       "24997  1#Rwanda#RW#RW#-2#30#RW;5#Gauteng, Gauteng, So...   \n",
       "24998  1#Mexico#MX#MX#23#-102#MX;2#New York, United S...   \n",
       "24999  4#Nairobi, Nairobi Area, Kenya#KE#KE05#-1.2833...   \n",
       "\n",
       "                                                 PERSONS  \\\n",
       "0                john okafor;kenneth okwonko;tonto dikeh   \n",
       "1                                                    NaN   \n",
       "2      millie odhiambo mbita;johanna ngeno emurua dik...   \n",
       "3                                       fernando wangila   \n",
       "4            esther ruto;africa allafrica;rusi cheruiyot   \n",
       "...                                                  ...   \n",
       "24995  musa mustapha;agnes mutiota;thomas nyakundi;os...   \n",
       "24996  natasha stott despoja;gideon kayinamura;mwai k...   \n",
       "24997           addis abeba;carlo ladicicco;sol campbell   \n",
       "24998  trudy coxe;jonathan soroff;jonathan kaye;iris ...   \n",
       "24999                   beatrice obwocha;boniface mwangi   \n",
       "\n",
       "                                           ORGANIZATIONS  \\\n",
       "0                                                    NaN   \n",
       "1      netherlands africa business council;africa eve...   \n",
       "2      orange democratic movement;nairobi county at k...   \n",
       "3          public service vehicles;technology management   \n",
       "4      comart foundation;coady international institut...   \n",
       "...                                                  ...   \n",
       "24995                              boundaries commission   \n",
       "24996  party leader australia professor pierre moukok...   \n",
       "24997           wide area networks;gauteng high court on   \n",
       "24998  preservation society;preservation society of n...   \n",
       "24999                                                NaN   \n",
       "\n",
       "                                                    TONE  \\\n",
       "0      2.83687943262411,4.25531914893617,1.4184397163...   \n",
       "1      2.04081632653061,2.33236151603499,0.2915451895...   \n",
       "2      -0.164473684210526,3.61842105263158,3.78289473...   \n",
       "3      -2.28571428571429,1.07142857142857,3.357142857...   \n",
       "4      2.76710222905457,3.38201383551115,0.6149116064...   \n",
       "...                                                  ...   \n",
       "24995  -2.45022970903522,1.07197549770291,3.522205206...   \n",
       "24996  0.574712643678161,3.06513409961686,2.490421455...   \n",
       "24997  0,3.07692307692308,3.07692307692308,6.15384615...   \n",
       "24998  6.04395604395604,7.14285714285714,1.0989010989...   \n",
       "24999  -1.92678227360308,2.89017341040462,4.816955684...   \n",
       "\n",
       "                                           CAMEOEVENTIDS  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2      672052169,672052170,672052205,672053130,672032...   \n",
       "3                                    672171132,672074694   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "24995            678753308,678754466,678754467,678754469   \n",
       "24996  678599092,678599093,678542527,678599437,678599...   \n",
       "24997                                                NaN   \n",
       "24998                                                NaN   \n",
       "24999  678546220,678609757,678591897,678609760,678564...   \n",
       "\n",
       "                       SOURCES  \\\n",
       "0      247nigerianewsupdate.co   \n",
       "1                      cta.int   \n",
       "2          sde.co.ke;sde.co.ke   \n",
       "3                 techweez.com   \n",
       "4             bizcommunity.com   \n",
       "...                        ...   \n",
       "24995      standardmedia.co.ke   \n",
       "24996          myjoyonline.com   \n",
       "24997              direct.news   \n",
       "24998             improper.com   \n",
       "24999                en.rfi.fr   \n",
       "\n",
       "                                              SOURCEURLS  \\\n",
       "0      http://www.247nigerianewsupdate.co/2017/07/see...   \n",
       "1      http://brussels.cta.int/index.php?option=com_k...   \n",
       "2      https://www.sde.co.ke/article/2001246965/how-k...   \n",
       "3      http://www.techweez.com/2017/07/11/ntsa-smart-...   \n",
       "4      http://www.bizcommunity.com/Article/196/356/16...   \n",
       "...                                                  ...   \n",
       "24995  https://www.standardmedia.co.ke/article/200125...   \n",
       "24996  https://www.myjoyonline.com/politics/2017/Augu...   \n",
       "24997             https://africa.direct.news/news=933349   \n",
       "24998  http://www.improper.com/photos-parties/newport...   \n",
       "24999  http://en.rfi.fr/africa/20170804-kenyan-activi...   \n",
       "\n",
       "                                               news_text  scraping_flag  \\\n",
       "0                               Unable to reach website.             -4   \n",
       "1                               Unable to reach website.             -4   \n",
       "2      Ida Odinga, Margaret Kenyatta and Rachel Ruto ...              1   \n",
       "3      Kenya’s National Transport and Safety Board (N...              1   \n",
       "4      By adopting agroforestry and improved agricult...              1   \n",
       "...                                                  ...            ...   \n",
       "24995                           Unable to reach website.             -4   \n",
       "24996                               No dict from scraper             -3   \n",
       "24997                                   No text returned             -5   \n",
       "24998                           Unable to reach website.             -4   \n",
       "24999                           Unable to reach website.             -4   \n",
       "\n",
       "       wbm_tag  \n",
       "0            0  \n",
       "1            0  \n",
       "2            1  \n",
       "3            1  \n",
       "4            0  \n",
       "...        ...  \n",
       "24995        0  \n",
       "24996        0  \n",
       "24997        1  \n",
       "24998        0  \n",
       "24999        0  \n",
       "\n",
       "[25000 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_news_latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-kaFdn8371-",
    "outputId": "0fa09f43-d35f-40b2-87a7-002615f6b1a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    13486\n",
       "-4     6215\n",
       "-3     4695\n",
       "-5      322\n",
       "-2      194\n",
       "-6       81\n",
       "-1        7\n",
       "Name: scraping_flag, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view success of scraper (1==success)\n",
    "\n",
    "country_news_latest.scraping_flag.value_counts()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "de5I7mg3vwON"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
