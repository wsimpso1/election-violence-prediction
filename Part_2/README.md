# Part 2: Election Violence-related News

The goal of Part 2 is to create a filter that selects global news articles most relevant to the top risk factors of election violence identified in Part 1. There are three steps to do this: 1) gather news data related to the country in question (i.e., Kenya); 2)  transform the text to vector representations via a pre-trained sentence embedding model; and 3) compute the cosine similarity of each article to each of the top election violence risk factor descriptions. For the first step, the GDELT GKG enables a simple pipeline to gather global news relating to a country in a specified time period. In total, 643,677 GKG news articles mentioning Kenya between 8 August 2016 and 28 November 2017 were downloaded from the GDELT GKG master list. This timeframe inclusively covers one year before Kenya’s 2017 national election and 3 months afterwards. A custom scraping script was used to pull the text content for each article. Since these articles are at least five years old, many URLs were no longer functioning. As a workaround, articles were scraped from the WayBack Machine which is a digital archive of billions of websites that have existed on the internet since 1996. The scraping script returned text for approximately 70% of articles, reducing the news dataset to 451,572 articles (88% from the WayBack Machine).

For the second step, sentence embeddings are highly effective techniques in NLP to represent sentences, including their syntactic and semantic information, as numeric vectors (Huilgol, 2022). Tensorflow’s Universal Sentence Encoder (USE) is employed to convert each news article and the textual descriptions of the election violence risk factors into fixed-length vector representations of 512 dimensions (Cer et al., 2018). Specifically, this study utilizes that deep averaging network (DAN) formulation of the USE. This version computes an average of all word and bigram embeddings for a text and then passes that output through a feedforward deep neural network to produce sentence embeddings. The DAN version is chosen due to its computational efficiency over the Transformer-based USE. 

The last step of Part 2 entails determining the similarity of each news article to each of the top risk factors of election violence. This is relatively straightforward with vector representations of the news articles and risk factor descriptions from NELDA. Cosine similarity is a measure of the cosine of the angle between two vectors in high dimensional space. When applied to text embeddings, a cosine similarity score of 1 would indicate that two pieces of text are identical, a score of 0 would mean they are orthogonal or unrelated, and a score of -1 indicates they are exact opposites. Articles with at least 20% similarity to at least two risk factors of election violence are kept and used as the input data to Part 3.   
